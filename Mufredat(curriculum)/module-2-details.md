# ğŸ¤– ModÃ¼l 2: Klasik Makine Ã–ÄŸrenmesi - DetaylÄ± MÃ¼fredat

Bu dokÃ¼man, mÃ¼fredatÄ±n 6. bÃ¶lÃ¼mÃ¼nden 12. bÃ¶lÃ¼mÃ¼ne kadar uzanan Klasik Makine Ã–ÄŸrenmesi sÃ¼recini kapsamaktadÄ±r. Her bÃ¶lÃ¼m iÃ§in Ã¶zel kaynaklar ve alÄ±ÅŸtÄ±rmalar satÄ±r bazlÄ± olarak dÃ¼zenlenmiÅŸtir.

---

## ğŸ—ºï¸ Kaynak ve MÃ¼fredat Matrisi (BÃ¶lÃ¼m 6 - 12)

AÅŸaÄŸÄ±daki tablo, Ã¶ÄŸrenim sÃ¼recinizdeki ana kaynaklarÄ±n hangi bÃ¶lÃ¼mleri kapsadÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

<table>
  <thead>
    <tr>
      <th>No</th>
      <th>BÃ¶lÃ¼m AdÄ±</th>
      <th>Ä°nternet Sitesi</th>
      <th>Medium / GfG</th>
      <th>Youtube</th>
      <th>AlÄ±ÅŸtÄ±rmalar</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td align="center"><b>6</b></td>
      <td>Makine Ã–ÄŸrenmesine GiriÅŸ</td>
      <td><a href="https://scikit-learn.org/stable/preface.html">Sklearn Intro</a></td>
      <td><a href="https://medium.com/topic/machine-learning">ML Basics</a></td>
      <td>StatQuest: ML Basics</td>
      <td>Kavramsal Test</td>
    </tr>
    <tr>
      <td align="center"><b>7</b></td>
      <td>ML Temelleri (Ã–n Ä°ÅŸleme)</td>
      <td><a href="https://scikit-learn.org/stable/modules/preprocessing.html">Preprocessing Guide</a></td>
      <td><a href="https://www.geeksforgeeks.org/data-preprocessing-machine-learning-python/">GfG Preprocessing</a></td>
      <td>Krish Naik: Preprocessing</td>
      <td>Scaling & Encoding Lab</td>
    </tr>
    <tr>
      <td align="center"><b>8</b></td>
      <td>Supervised Learning - Regresyon</td>
      <td><a href="https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html">Reg. Cheatsheet</a></td>
      <td><a href="https://towardsdatascience.com/linear-regression-detailed-view-ea73175f5950">Linear Reg. Detail</a></td>
      <td>Andrew Ng: Regression</td>
      <td><b>SÄ±fÄ±rdan (Scratch) Kodlama</b></td>
    </tr>
    <tr>
      <td align="center"><b>9</b></td>
      <td>Supervised Learning - SÄ±nÄ±flandÄ±rma</td>
      <td><a href="https://scikit-learn.org/stable/modules/tree.html">Decision Trees</a></td>
      <td><a href="https://www.geeksforgeeks.org/classification-in-machine-learning/">Classification Guide</a></td>
      <td>StatQuest: SVM & Trees</td>
      <td><b>SÄ±fÄ±rdan (Scratch) k-NN</b></td>
    </tr>
    <tr>
      <td align="center"><b>10</b></td>
      <td>Ensemble Methods</td>
      <td><a href="https://xgboost.readthedocs.io/">XGBoost Docs</a></td>
      <td><a href="https://medium.com/tag/ensemble-learning">Ensemble Mastery</a></td>
      <td>Corey Schafer: Random Forest</td>
      <td>XGBoost vs RF Lab</td>
    </tr>
    <tr>
      <td align="center"><b>11</b></td>
      <td>Unsupervised Learning</td>
      <td><a href="https://scikit-learn.org/stable/modules/clustering.html">Clustering Guide</a></td>
      <td><a href="https://www.geeksforgeeks.org/clustering-in-machine-learning/">GfG Clustering</a></td>
      <td>Sentdex: PCA</td>
      <td><b>SÄ±fÄ±rdan (Scratch) K-Means</b></td>
    </tr>
    <tr>
      <td align="center"><b>12</b></td>
      <td>Model DeÄŸerlendirme ve SeÃ§imi</td>
      <td><a href="https://scikit-learn.org/stable/modules/model_evaluation.html">Metrics Guide</a></td>
      <td><a href="https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f1043830c5c8">Evaluation Metrics</a></td>
      <td>StatQuest: ROC-AUC</td>
      <td>Hyperparameter Tuning Lab</td>
    </tr>
  </tbody>
</table>

---

## ğŸ“‹ Teknik Alt BaÅŸlÄ±klar (SÄ±ralÄ± MÃ¼fredat)



### 6. Makine Ã–ÄŸrenmesine GiriÅŸ
* **6-1-1.** Makine Ã¶ÄŸrenmesi nedir?
* **6-1-2.** Denetimli vs Denetimsiz Ã¶ÄŸrenme teorisi.
* **6-1-4.** EÄŸitim, doÄŸrulama ve test kÃ¼meleri mantÄ±ÄŸÄ±.
* **6-2-1.** Lineer Regresyon ve Multiple Lineer Regresyon giriÅŸ.

### 7. Makine Ã–ÄŸrenmesi Temelleri
* **7-1-3.** Overfitting ve underfitting tespiti.
* **7-1-4.** Bias-variance tradeoff dengesi.
* **7-2-1.** Feature scaling (normalization, standardization) teknikleri.
* **7-2-2.** Veri kodlama (one-hot, label encoding).

### 8. Supervised Learning - Regresyon
* **8-1-1.** En kÃ¼Ã§Ã¼k kareler (least squares) matematiksel temeli.
* **8-1-2.** Gradient descent algoritmasÄ± iÅŸleyiÅŸi.
* **8-1-3.** **SÄ±fÄ±rdan Python implementasyonu (KÃ¼tÃ¼phanesiz).**
* **8-3-1.** $L1$ (Lasso) ve $L2$ (Ridge) regularization farklarÄ±.

### 9. Supervised Learning - SÄ±nÄ±flandÄ±rma
* **9-1-1.** Mesafe metrikleri (Euclidean, Manhattan).
* **9-2-1.** Information gain ve entropy hesaplamalarÄ±.
* **9-3-2.** Kernel trick matematiksel altyapÄ±sÄ± (SVM).
* **9-4-1.** Bayes Teoremi ve olasÄ±lÄ±ksal sÄ±nÄ±flandÄ±rma.

### 10. Ensemble Methods
* **10-1-1.** Bootstrap sampling ve Bagging mantÄ±ÄŸÄ±.
* **10-1-4.** **SÄ±fÄ±rdan Random Forest implementasyonu.**
* **10-2-2.** Gradient Boosting ve XGBoost/LightGBM kullanÄ±mÄ±.

### 11. Unsupervised Learning
* **11-1-1.** K-means algoritmasÄ± ve yakÄ±nsama (convergence).
* **11-1-5.** **SÄ±fÄ±rdan k-means implementasyonu.**
* **11-2-1.** PCA (Principal Component Analysis) ve Eigenvalue hesaplamalarÄ±.

### 12. Model DeÄŸerlendirme ve SeÃ§imi
* **12-1-1.** Accuracy, Precision, Recall ve F1-Score metrikleri.
* **12-1-2.** ROC curve ve AUC alanÄ± analizi.
* **12-2-1.** Grid Search ve Random Search ile hiperparametre optimizasyonu.

---
> **Ã–nemli:** ModÃ¼l 2 projelerinizi teslim ederken "SÄ±fÄ±rdan Kodlama" (Scratch) bÃ¶lÃ¼mlerine Ã¶ncelik veriniz.
---
