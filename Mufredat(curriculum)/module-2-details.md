# ğŸ¤– ModÃ¼l 2: Klasik Makine Ã–ÄŸrenmesi - DetaylÄ± MÃ¼fredat

Bu dokÃ¼man, mÃ¼fredatÄ±n 6. bÃ¶lÃ¼mÃ¼nden 12. bÃ¶lÃ¼mÃ¼ne kadar uzanan Klasik Makine Ã–ÄŸrenmesi sÃ¼recini kapsamaktadÄ±r. Her bÃ¶lÃ¼m iÃ§in Ã¶zel kaynaklar ve alÄ±ÅŸtÄ±rmalar satÄ±r bazlÄ± olarak dÃ¼zenlenmiÅŸtir.


## ğŸ—ºï¸ Kaynak ve MÃ¼fredat Matrisi

### ğŸ¤– 6. & 7. ModÃ¼l: Makine Ã–ÄŸrenmesine GiriÅŸ & Temeller
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi | 
|:---|:---|:---|:---|:---|:---|
| **6.1 & 7.1** | ML Temel KavramlarÄ± (Teori) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=YouTube&logoColor=white)](https://www.youtube.com/playlist?list=PL3ED48mWmYxrAdWjQlOWzFNaM4gLgry5T) | [![Scikit-learn](https://img.shields.io/badge/-scikit--learn-%23F7931E?logo=scikit-learn&logoColor=white)](https://scikit-learn.org/stable/supervised_learning.html) | [![Medium](https://img.shields.io/badge/Medium-black?logo=medium&logoColor=white)](https://medium.com/machine-learning-tÃ¼rkiye/makine-ogrenmesi-7cfbb3d859db) [![Medium](https://img.shields.io/badge/Medium-black?logo=medium&logoColor=white)](https://medium.com/@onurkasap/scikit-learne-giriÅŸ-08f5812791b1) [![GeeksForGeeks](https://img.shields.io/badge/GeeksforGeeks-298D46?logo=geeksforgeeks&logoColor=white)](https://www.geeksforgeeks.org/machine-learning/what-is-python-scikit-library/) | [![Google Developers](https://img.shields.io/badge/Google%20Developers-%23202124.svg?style=for-the-badge&logo=google-developers&logoColor=white)](https://developers.google.com/machine-learning?hl=tr) | 
| **7.2** | Veri Ã–n Ä°ÅŸleme (Preprocessing) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IR14hDWQVU0) | [![Scikit-learn](https://img.shields.io/badge/-scikit--learn-%23F7931E?logo=scikit-learn&logoColor=white)](https://scikit-learn.org/stable/data_transforms.html) | [![Medium](https://img.shields.io/badge/Medium-black?logo=medium&logoColor=white)](https://medium.com/@denizkilinc/python-ile-veri-Ã¶n-iÌ‡ÅŸlemeye-dalÄ±ÅŸ-f89f921658bd) [![GeeksForGeeks](https://img.shields.io/badge/GeeksforGeeks-298D46?logo=geeksforgeeks&logoColor=white)](https://www.geeksforgeeks.org/machine-learning/what-is-data-normalization/) | [![Coursera](https://img.shields.io/badge/Coursera-0056D2?logo=coursera&logoColor=fff)](https://www.coursera.org/specializations/machine-learning-introduction) |

---

### ğŸ“ˆ 8. ModÃ¼l: Supervised Learning - Regresyon
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi |
|:---|:---|:---|:---|:---|:---|
| **8-1** | Lineer Regresyon (Matematik & Uygulama) | [Link] | [Link] | [Link] | [Link] | 
| **8-2** | Polinomial Regresyon | [Link] | [Link] | [Link] | [Link] | [Ã–dev] |
| **8-3** | Regularization (Ridge, Lasso, Elastic Net) | [Link] | [Link] | [Link] | [Link] | 
| **8-4** | Lojistik Regresyon | [Link] | [Link] | [Link] | [Link] | 

---

### ğŸ¯ 9. ModÃ¼l: Supervised Learning - SÄ±nÄ±flandÄ±rma
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi | 
|:---|:---|:---|:---|:---|:---|
| **9-1** | k-Nearest Neighbors (k-NN) | [Link] | [Link] | [Link] | [Link] | 
| **9-2** | Karar AÄŸaÃ§larÄ± (Decision Trees) | [Link] | [Link] | [Link] | [Link] | 
| **9-3** | Support Vector Machines (SVM) | [Link] | [Link] | [Link] | [Link] | 
| **9-4** | Naive Bayes | [Link] | [Link] | [Link] | [Link] |

---

### ğŸŒ² 10. ModÃ¼l: Ensemble Methods (Topluluk YÃ¶ntemleri)
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi |
|:---|:---|:---|:---|:---|:---|
| **10-1** | Bagging ve Random Forest | [Link] | [Link] | [Link] | [Link] | 
| **10-2** | Boosting (XGBoost, LightGBM, CatBoost) | [Link] | [Link] | [Link] | [Link] |

---

### ğŸ” 11. ModÃ¼l: Unsupervised Learning
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi | 
|:---|:---|:---|:---|:---|:---|
| **11-1** | KÃ¼meleme (K-means, Hierarchical, DBSCAN) | [Link] | [Link] | [Link] | [Link] | 
| **11-2** | Boyut Azaltma (PCA, SVD, t-SNE) | [Link] | [Link] | [Link] | [Link] |

---

### ğŸ“ 12. ModÃ¼l: DeÄŸerlendirme ve Model SeÃ§imi
| No | Konu BaÅŸlÄ±ÄŸÄ± | ğŸ“º Video | ğŸ“– DokÃ¼man | ğŸ“ Medium & GfG | ğŸ“ EÄŸitim Serisi |
|:---|:---|:---|:---|:---|:---|
| **12-1** | DeÄŸerlendirme Metrikleri (ROC, AUC, F1) | [Link] | [Link] | [Link] | [Link] | 
| **12-2** | Model SeÃ§imi & Hiperparametre Tuning | [Link] | [Link] | [Link] | [Link] |

---

### ğŸ† Final Projesi: ML
| Proje BaÅŸlÄ±ÄŸÄ± | AÃ§Ä±klama | Kaynak Veri | Teslim Linki |
|:---|:---|:---|:---|
| **UÃ§tan Uca Makine Ã–ÄŸrenmesi HattÄ±** | Veri Ã¶n iÅŸlemeden model daÄŸÄ±tÄ±mÄ±na kadar tÃ¼m sÃ¼reÃ§. | [Veri Seti] | [Repo] |

---


## ğŸ“‹ Teknik Alt BaÅŸlÄ±klar (Makine Ã–ÄŸrenmesi ModÃ¼lleri)

### ğŸ¤– 6 & 7. Makine Ã–ÄŸrenmesi Temelleri ve GiriÅŸ

* **6-1 & 7-1. Makine Ã–ÄŸrenmesi Temel KavramlarÄ±**
    * 6-1-1. Makine Ã¶ÄŸrenmesi nedir? Temel paradigmalar.
    * 6-1-2. Denetimli (Supervised) vs Denetimsiz (Unsupervised) Ã¶ÄŸrenme teorisi.
    * 6-1-3. SÄ±nÄ±flandÄ±rma (Classification) vs Regresyon (Regression) farklarÄ±.
    * 6-1-4. Veri Seti BÃ¶lme: EÄŸitim (Training), DoÄŸrulama (Validation) ve Test kÃ¼meleri.
    * 6-1-5. Model HatalarÄ±: AÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) ve Az Ã¶ÄŸrenme (Underfitting).
    * 7-1-4. Bias-Variance Tradeoff (YanlÄ±lÄ±k-Varyans Dengesi).
    * 7-1-5. Ã‡apraz DoÄŸrulama (Cross-Validation) teknikleri.
* **7-2. Veri Ã–n Ä°ÅŸleme (Preprocessing)**
    * 7-2-1. Ã–zellik Ã–lÃ§eklendirme (Feature Scaling): Normalization ve Standardization.
    * 7-2-2. Kategorik Veri Kodlama: One-Hot Encoding ve Label Encoding.
    * 7-2-3. Ã–zellik SeÃ§imi (Feature Selection) yÃ¶ntemleri.
    * 7-2-4. Boyut Azaltma (Dimensionality Reduction) temel kavramlarÄ±.


---

### ğŸ“ˆ 8. Supervised Learning - Regresyon

* **8-1. Lineer Regresyon**
    * 8-1-1. Matematiksel Temeller: En KÃ¼Ã§Ã¼k Kareler YÃ¶ntemi (Least Squares).
    * 8-1-2. Gradient Descent (Dereceli AzaltÄ±m) algoritmasÄ±.
    * 8-1-3. SÄ±fÄ±rdan Python implementasyonu ve Sklearn uygulamasÄ±.
    * 8-1-5. Model DeÄŸerlendirme Metrikleri: $MSE$, $RMSE$ ve $R^2$.
* **8-2. Polinomial Regresyon**
    * 8-2-1. Polinomial Ã¶zellik dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve non-lineer iliÅŸkiler.
* **8-3. Regularization (DÃ¼zenlileÅŸtirme)**
    * 8-3-1. $L_1$ (Lasso) ve $L_2$ (Ridge) regularization matematiksel altyapÄ±sÄ±.
    * 8-3-2. Elastic Net kombinasyonu ve sÄ±fÄ±rdan implementasyon.
* **8-4. Lojistik Regresyon (SÄ±nÄ±flandÄ±rma Temelli)**
    * 8-4-1. Sigmoid Fonksiyonu ve matematiksel analizi.
    * 8-4-2. Maksimum Olabilirlik Kestirimi (Maximum Likelihood Estimation).
    * 8-4-4. SÄ±fÄ±rdan implementasyon ve Multi-class (Ã‡ok sÄ±nÄ±flÄ±) sÄ±nÄ±flandÄ±rma.



---

### ğŸ¯ 9. Supervised Learning - SÄ±nÄ±flandÄ±rma

* **9-1. k-Nearest Neighbors (k-NN)**
    * 9-1-1. Mesafe Metrikleri (Euclidean, Manhattan, Minkowski).
    * 9-1-2. Optimal "k" seÃ§imi ve Boyut Laneti (Curse of Dimensionality).
* **9-2. Karar AÄŸaÃ§larÄ± (Decision Trees)**
    * 9-2-1. Bilgi KazancÄ± (Information Gain) ve Entropi (Entropy).
    * 9-2-2. Gini SaflÄ±ÄŸÄ± (Gini Impurity).
    * 9-2-4. Budama (Pruning) teknikleri ile overfitting engelleme.
* **9-3. Support Vector Machines (SVM)**
    * 9-3-1. Hiper dÃ¼zlem (Hyperplane) ve Destek VektÃ¶rleri (Support Vectors).
    * 9-3-2. Kernel Trick (Ã‡ekirdek YÃ¶ntemi) matematiksel altyapÄ±sÄ±.
    * 9-3-3. Soft Margin ve Dual FormÃ¼lasyon.
* **9-4. Naive Bayes**
    * 9-4-1. Bayes Teoremi ve olasÄ±lÄ±ksal yaklaÅŸÄ±m.
    * 9-4-2. Varyasyonlar: Gaussian, Multinomial ve Bernoulli NB.
    * 9-4-3. Laplace Smoothing (DÃ¼zleÅŸtirme).



---

### ğŸŒ² 10. Ensemble Methods (Topluluk YÃ¶ntemleri)

* **10-1. Bagging ve Random Forest**
    * 10-1-1. Bootstrap Sampling ve Aggregation mantÄ±ÄŸÄ±.
    * 10-1-2. Rastgele Alt Uzay (Random Subspace) yÃ¶ntemi.
    * 10-1-3. Ã–zellik Ã–nem SÄ±rasÄ± (Feature Importance) hesaplama.
* **10-2. Boosting**
    * 10-2-1. AdaBoost algoritmasÄ± ve matematiksel iÅŸleyiÅŸi.
    * 10-2-2. Gradient Boosting temel prensipleri.
    * 10-2-3. Modern KÃ¼tÃ¼phaneler: XGBoost, LightGBM ve CatBoost kullanÄ±mÄ±.

---

### ğŸ” 11. Unsupervised Learning (Denetimsiz Ã–ÄŸrenme)

* **11-1. KÃ¼meleme (Clustering)**
    * 11-1-1. K-means AlgoritmasÄ±: YakÄ±nsama (Convergence) ve Elbow Metodu.
    * 11-1-2. HiyerarÅŸik KÃ¼meleme (Hierarchical Clustering) ve Dendrogramlar.
    * 11-1-3. YoÄŸunluk TabanlÄ± KÃ¼meleme (DBSCAN).
    * 11-1-4. KÃ¼me DeÄŸerlendirme: Silhouette Score.
* **11-2. Boyut Azaltma (Dimensionality Reduction)**
    * 11-2-1. Temel BileÅŸen Analizi (PCA).
    * 11-2-2. Ã–zdeÄŸer (Eigenvalue) ve Ã–zvektÃ¶r (Eigenvector) ayrÄ±ÅŸÄ±mÄ±.
    * 11-2-3. Tekil DeÄŸer AyrÄ±ÅŸÄ±mÄ± (SVD).
    * 11-2-4. t-SNE algoritmasÄ± ile gÃ¶rselleÅŸtirme temelleri.



---

### ğŸ“ 12. Model DeÄŸerlendirme ve SeÃ§imi

* **12-1. DeÄŸerlendirme Metrikleri**
    * 12-1-1. SÄ±nÄ±flandÄ±rma: Accuracy, Precision, Recall ve F1-Score.
    * 12-1-2. ROC EÄŸrisi ve AUC (Area Under Curve) analizi.
    * 12-1-3. Hata Matrisi (Confusion Matrix) okuma.
    * 12-1-4. Regresyon metriklerinin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±.
* **12-2. Model SeÃ§imi ve Hiperparametre Optimizasyonu**
    * 12-2-1. Arama Stratejileri: Grid Search ve Random Search.
    * 12-2-3. Ã–ÄŸrenme EÄŸrileri (Learning Curves) analizi.
    * 12-2-4. Hiperparametre Ayarlama (Hyperparameter Tuning).

### ğŸ¤– 6 & 7. Makine Ã–ÄŸrenmesi Temelleri ve GiriÅŸ

* **6-1 & 7-1. Makine Ã–ÄŸrenmesi Temel KavramlarÄ±**
    * 6-1-1. Makine Ã¶ÄŸrenmesi nedir? Temel paradigmalar.
    * 6-1-2. Denetimli (Supervised) vs Denetimsiz (Unsupervised) Ã¶ÄŸrenme teorisi.
    * 6-1-3. SÄ±nÄ±flandÄ±rma (Classification) vs Regresyon (Regression) farklarÄ±.
    * 6-1-4. Veri Seti BÃ¶lme: EÄŸitim (Training), DoÄŸrulama (Validation) ve Test kÃ¼meleri.
    * 6-1-5. Model HatalarÄ±: AÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) ve Az Ã¶ÄŸrenme (Underfitting).
    * 7-1-4. Bias-Variance Tradeoff (YanlÄ±lÄ±k-Varyans Dengesi).
    * 7-1-5. Ã‡apraz DoÄŸrulama (Cross-Validation) teknikleri.
* **7-2. Veri Ã–n Ä°ÅŸleme (Preprocessing)**
    * 7-2-1. Ã–zellik Ã–lÃ§eklendirme (Feature Scaling): Normalization ve Standardization.
    * 7-2-2. Kategorik Veri Kodlama: One-Hot Encoding ve Label Encoding.
    * 7-2-3. Ã–zellik SeÃ§imi (Feature Selection) yÃ¶ntemleri.
    * 7-2-4. Boyut Azaltma (Dimensionality Reduction) temel kavramlarÄ±.


---

### ğŸ“ˆ 8. Supervised Learning - Regresyon

* **8-1. Lineer Regresyon**
    * 8-1-1. Matematiksel Temeller: En KÃ¼Ã§Ã¼k Kareler YÃ¶ntemi (Least Squares).
    * 8-1-2. Gradient Descent (Dereceli AzaltÄ±m) algoritmasÄ±.
    * 8-1-3. SÄ±fÄ±rdan Python implementasyonu ve Sklearn uygulamasÄ±.
    * 8-1-5. Model DeÄŸerlendirme Metrikleri: $MSE$, $RMSE$ ve $R^2$.
* **8-2. Polinomial Regresyon**
    * 8-2-1. Polinomial Ã¶zellik dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve non-lineer iliÅŸkiler.
* **8-3. Regularization (DÃ¼zenlileÅŸtirme)**
    * 8-3-1. $L_1$ (Lasso) ve $L_2$ (Ridge) regularization matematiksel altyapÄ±sÄ±.
    * 8-3-2. Elastic Net kombinasyonu ve sÄ±fÄ±rdan implementasyon.
* **8-4. Lojistik Regresyon (SÄ±nÄ±flandÄ±rma Temelli)**
    * 8-4-1. Sigmoid Fonksiyonu ve matematiksel analizi.
    * 8-4-2. Maksimum Olabilirlik Kestirimi (Maximum Likelihood Estimation).
    * 8-4-4. SÄ±fÄ±rdan implementasyon ve Multi-class (Ã‡ok sÄ±nÄ±flÄ±) sÄ±nÄ±flandÄ±rma.



---

### ğŸ¯ 9. Supervised Learning - SÄ±nÄ±flandÄ±rma

* **9-1. k-Nearest Neighbors (k-NN)**
    * 9-1-1. Mesafe Metrikleri (Euclidean, Manhattan, Minkowski).
    * 9-1-2. Optimal "k" seÃ§imi ve Boyut Laneti (Curse of Dimensionality).
* **9-2. Karar AÄŸaÃ§larÄ± (Decision Trees)**
    * 9-2-1. Bilgi KazancÄ± (Information Gain) ve Entropi (Entropy).
    * 9-2-2. Gini SaflÄ±ÄŸÄ± (Gini Impurity).
    * 9-2-4. Budama (Pruning) teknikleri ile overfitting engelleme.
* **9-3. Support Vector Machines (SVM)**
    * 9-3-1. Hiper dÃ¼zlem (Hyperplane) ve Destek VektÃ¶rleri (Support Vectors).
    * 9-3-2. Kernel Trick (Ã‡ekirdek YÃ¶ntemi) matematiksel altyapÄ±sÄ±.
    * 9-3-3. Soft Margin ve Dual FormÃ¼lasyon.
* **9-4. Naive Bayes**
    * 9-4-1. Bayes Teoremi ve olasÄ±lÄ±ksal yaklaÅŸÄ±m.
    * 9-4-2. Varyasyonlar: Gaussian, Multinomial ve Bernoulli NB.
    * 9-4-3. Laplace Smoothing (DÃ¼zleÅŸtirme).



---

### ğŸŒ² 10. Ensemble Methods (Topluluk YÃ¶ntemleri)

* **10-1. Bagging ve Random Forest**
    * 10-1-1. Bootstrap Sampling ve Aggregation mantÄ±ÄŸÄ±.
    * 10-1-2. Rastgele Alt Uzay (Random Subspace) yÃ¶ntemi.
    * 10-1-3. Ã–zellik Ã–nem SÄ±rasÄ± (Feature Importance) hesaplama.
* **10-2. Boosting**
    * 10-2-1. AdaBoost algoritmasÄ± ve matematiksel iÅŸleyiÅŸi.
    * 10-2-2. Gradient Boosting temel prensipleri.
    * 10-2-3. Modern KÃ¼tÃ¼phaneler: XGBoost, LightGBM ve CatBoost kullanÄ±mÄ±.

---

### ğŸ” 11. Unsupervised Learning (Denetimsiz Ã–ÄŸrenme)

* **11-1. KÃ¼meleme (Clustering)**
    * 11-1-1. K-means AlgoritmasÄ±: YakÄ±nsama (Convergence) ve Elbow Metodu.
    * 11-1-2. HiyerarÅŸik KÃ¼meleme (Hierarchical Clustering) ve Dendrogramlar.
    * 11-1-3. YoÄŸunluk TabanlÄ± KÃ¼meleme (DBSCAN).
    * 11-1-4. KÃ¼me DeÄŸerlendirme: Silhouette Score.
* **11-2. Boyut Azaltma (Dimensionality Reduction)**
    * 11-2-1. Temel BileÅŸen Analizi (PCA).
    * 11-2-2. Ã–zdeÄŸer (Eigenvalue) ve Ã–zvektÃ¶r (Eigenvector) ayrÄ±ÅŸÄ±mÄ±.
    * 11-2-3. Tekil DeÄŸer AyrÄ±ÅŸÄ±mÄ± (SVD).
    * 11-2-4. t-SNE algoritmasÄ± ile gÃ¶rselleÅŸtirme temelleri.



---

### ğŸ“ 12. Model DeÄŸerlendirme ve SeÃ§imi

* **12-1. DeÄŸerlendirme Metrikleri**
    * 12-1-1. SÄ±nÄ±flandÄ±rma: Accuracy, Precision, Recall ve F1-Score.
    * 12-1-2. ROC EÄŸrisi ve AUC (Area Under Curve) analizi.
    * 12-1-3. Hata Matrisi (Confusion Matrix) okuma.
    * 12-1-4. Regresyon metriklerinin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±.
* **12-2. Model SeÃ§imi ve Hiperparametre Optimizasyonu**
    * 12-2-1. Arama Stratejileri: Grid Search ve Random Search.
    * 12-2-3. Ã–ÄŸrenme EÄŸrileri (Learning Curves) analizi.
    * 12-2-4. Hiperparametre Ayarlama (Hyperparameter Tuning).